<head>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>

<a href="https://github.com/elsanns/xai-nlp-notebooks/" target="_blank">repo</a> 
<a href="https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_explain_captum_ig.ipynb" target="_blank">Colab notebook</a>

<h2 id="-a-name-electraig-anchor-fine-tuning-electra-and-interpreting-with-captum-integrated-gradients-a-">Fine-tuning Electra and interpreting with Captum Integrated Gradients</h2>
<hr>
<p>This notebook contains an example of <a href="https://huggingface.co/transformers/training.html" target="_blank">fine-tuning</a> an <a href="https://huggingface.co/transformers/model_doc/electra.html" target="_blank">Electra</a> model on the <a href="https://nlp.stanford.edu/sentiment/index.html" target="_blank">GLUE SST-2</a> dataset. After fine-tuning, the <a href="https://arxiv.org/pdf/1703.01365.pdf" target="_blank">Integrated Gradients</a> <strong>interpretability</strong> method is applied to compute tokens&#39; attributions for each target class. </p>
<ul>
<li>We will instantiate a pre-trained Electra model from the <a href="https://huggingface.co/transformers/" target="_blank">Transformers</a> library. </li>
<li>The data is downloaded from the <a href="https://huggingface.co/nlp/" target="_blank">nlp</a> library. The input text is tokenized with <a href="https://huggingface.co/transformers/model_doc/electra.html#electratokenizerfast" target="_blank">ElectraTokenizerFast</a> tokenizer backed by HF <a href="https://huggingface.co/transformers/main_classes/tokenizer.html" target="_blank">tokenizers</a> library.</li>
<li><strong>Fine-tuning</strong> for sentiment analysis is handled by the <a href="https://huggingface.co/transformers/main_classes/trainer.html" target="_blank">Trainer</a> class. </li>
<li>After fine-tuning, the <a href="https://captum.ai/api/integrated_gradients.html" target="_blank">Integrated Gradients</a> interpretability algorithm will assign importance scores to
input tokens. We will use a <strong>PyTorch</strong> implementation from the <a href="https://captum.ai/" target="_blank">Captum</a> library. <ul>
<li>The algorithm requires providing a reference sample (a baseline) since importance attribution is performed based on the model&#39;s output, as inputs change from reference values to the actual sample. </li>
<li>The Integrated Gradients method satisfies the <a href="http://theory.stanford.edu/~ataly/Talks/sri_attribution_talk_jun_2017.pdf" target="_blank">completeness</a> property. We will look at the sum of attributions for a sample and show that the sum approximates (explains) prediction&#39;s shift from the baseline value. </li>
</ul>
</li>
<li>The final sections of this notebook contain a colour-coded <strong>visualization</strong> of attribution results made with <em>captum.attr.visualization</em> library.</li>
</ul>
<p>The notebook is based on the <a href="https://huggingface.co/" target="_blank">Hugging Face documentation</a> and the implementation of Integrated Gradients attribution methods is adapted from the Captum.ai
<a href="https://captum.ai/tutorials/Bert_SQUAD_Interpret" target="_blank">Interpreting BERT Models (Part 1)</a>.</p>
<p>
<h3 id="visualization">Visualization</h3>
Captum visualization library shows in green tokens that push the prediction towards the target class. Those driving the score towards the reference value are marked in red. As a result, words perceived as positive will appear in green if attribution is performed against class 1 (positive) but will be highlighted in red with an attribution targeting class 0 (negative).

Because importance scores ar assigned to tokens, not words, some examples may show that attribution is highly dependent on tokenization.
</p>
<h3 id="attributions-for-a-correctly-classified-positive-example">Attributions for a correctly classified positive example</h3>
<hr>
<p><img src="/imgs/xai-nlp-notebooks/electra-attr-positive-positive.png" width="800px" style="max-width:100%"></p>
<h3 id="attributions-for-a-correctly-classified-negative-example">Attributions for a correctly classified negative example</h3>
<hr>
<p><img src="/imgs/xai-nlp-notebooks/electra-attr-negative-negative.png" width="800px" style="max-width:100%"></p>
<h3 id="attributions-for-a-negative-sample-misclassified-as-positive">Attributions for a negative sample misclassified as positive</h3>
<hr>
<p><img src="/imgs/xai-nlp-notebooks/electra-attr-negative-positive.png" width="800px" style="max-width:100%"></p>
